{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%206/images/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
    "</center>\n",
    "\n",
    "# Classification with Python\n",
    "\n",
    "Estimated time needed: **25** minutes\n",
    "\n",
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "*   Confidently create classification models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this notebook we try to practice all the classification algorithms that we learned in this course.\n",
    "\n",
    "We load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n",
    "\n",
    "Let's first load required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### About dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This dataset is about the performance of basketball teams. The **cbb.csv** data set includes performance data about five seasons of 354 basketball teams. It includes following fields:\n",
    "\n",
    "| Field          | Description                                                                           |\n",
    "|----------------|---------------------------------------------------------------------------------------|\n",
    "|TEAM |\tThe Division I college basketball school|\n",
    "|CONF|\tThe Athletic Conference in which the school participates in (A10 = Atlantic 10, ACC = Atlantic Coast Conference, AE = America East, Amer = American, ASun = ASUN, B10 = Big Ten, B12 = Big 12, BE = Big East, BSky = Big Sky, BSth = Big South, BW = Big West, CAA = Colonial Athletic Association, CUSA = Conference USA, Horz = Horizon League, Ivy = Ivy League, MAAC = Metro Atlantic Athletic Conference, MAC = Mid-American Conference, MEAC = Mid-Eastern Athletic Conference, MVC = Missouri Valley Conference, MWC = Mountain West, NEC = Northeast Conference, OVC = Ohio Valley Conference, P12 = Pac-12, Pat = Patriot League, SB = Sun Belt, SC = Southern Conference, SEC = South Eastern Conference, Slnd = Southland Conference, Sum = Summit League, SWAC = Southwestern Athletic Conference, WAC = Western Athletic Conference, WCC = West Coast Conference)|\n",
    "|G|\tNumber of games played|\n",
    "|W|\tNumber of games won|\n",
    "|ADJOE|\tAdjusted Offensive Efficiency (An estimate of the offensive efficiency (points scored per 100 possessions) a team would have against the average Division I defense)|\n",
    "|ADJDE|\tAdjusted Defensive Efficiency (An estimate of the defensive efficiency (points allowed per 100 possessions) a team would have against the average Division I offense)|\n",
    "|BARTHAG|\tPower Rating (Chance of beating an average Division I team)|\n",
    "|EFG_O|\tEffective Field Goal Percentage Shot|\n",
    "|EFG_D|\tEffective Field Goal Percentage Allowed|\n",
    "|TOR|\tTurnover Percentage Allowed (Turnover Rate)|\n",
    "|TORD|\tTurnover Percentage Committed (Steal Rate)|\n",
    "|ORB|\tOffensive Rebound Percentage|\n",
    "|DRB|\tDefensive Rebound Percentage|\n",
    "|FTR|\tFree Throw Rate (How often the given team shoots Free Throws)|\n",
    "|FTRD|\tFree Throw Rate Allowed|\n",
    "|2P_O|\tTwo-Point Shooting Percentage|\n",
    "|2P_D|\tTwo-Point Shooting Percentage Allowed|\n",
    "|3P_O|\tThree-Point Shooting Percentage|\n",
    "|3P_D|\tThree-Point Shooting Percentage Allowed|\n",
    "|ADJ_T|\tAdjusted Tempo (An estimate of the tempo (possessions per 40 minutes) a team would have against the team that wants to play at an average Division I tempo)|\n",
    "|WAB|\tWins Above Bubble (The bubble refers to the cut off between making the NCAA March Madness Tournament and not making it)|\n",
    "|POSTSEASON|\tRound where the given team was eliminated or where their season ended (R68 = First Four, R64 = Round of 64, R32 = Round of 32, S16 = Sweet Sixteen, E8 = Elite Eight, F4 = Final Four, 2ND = Runner-up, Champion = Winner of the NCAA March Madness Tournament for that given year)|\n",
    "|SEED|\tSeed in the NCAA March Madness Tournament|\n",
    "|YEAR|\tSeason\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Load Data From CSV File\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's load the dataset \\[NB Need to provide link to csv file]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>...</th>\n",
       "      <th>FTRD</th>\n",
       "      <th>2P_O</th>\n",
       "      <th>2P_D</th>\n",
       "      <th>3P_O</th>\n",
       "      <th>3P_D</th>\n",
       "      <th>ADJ_T</th>\n",
       "      <th>WAB</th>\n",
       "      <th>POSTSEASON</th>\n",
       "      <th>SEED</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>ACC</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>123.3</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>52.6</td>\n",
       "      <td>48.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>30.4</td>\n",
       "      <td>53.9</td>\n",
       "      <td>44.6</td>\n",
       "      <td>32.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>71.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2ND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Villanova</td>\n",
       "      <td>BE</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>123.1</td>\n",
       "      <td>90.9</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>56.1</td>\n",
       "      <td>46.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57.4</td>\n",
       "      <td>44.1</td>\n",
       "      <td>36.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>66.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Champions</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>ACC</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>118.3</td>\n",
       "      <td>103.3</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>54.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>52.9</td>\n",
       "      <td>46.5</td>\n",
       "      <td>37.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>65.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>E8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>ACC</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>119.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>54.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>...</td>\n",
       "      <td>33.4</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.3</td>\n",
       "      <td>40.3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>61.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>B12</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>120.9</td>\n",
       "      <td>90.4</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>55.7</td>\n",
       "      <td>45.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>...</td>\n",
       "      <td>37.3</td>\n",
       "      <td>52.7</td>\n",
       "      <td>43.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>70.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TEAM CONF   G   W  ADJOE  ADJDE  BARTHAG  EFG_O  EFG_D   TOR  \\\n",
       "0  North Carolina  ACC  40  33  123.3   94.9   0.9531   52.6   48.1  15.4   \n",
       "1       Villanova   BE  40  35  123.1   90.9   0.9703   56.1   46.7  16.3   \n",
       "2      Notre Dame  ACC  36  24  118.3  103.3   0.8269   54.0   49.5  15.3   \n",
       "3        Virginia  ACC  37  29  119.9   91.0   0.9600   54.8   48.4  15.1   \n",
       "4          Kansas  B12  37  32  120.9   90.4   0.9662   55.7   45.1  17.8   \n",
       "\n",
       "   ...  FTRD  2P_O  2P_D  3P_O  3P_D  ADJ_T   WAB  POSTSEASON  SEED  YEAR  \n",
       "0  ...  30.4  53.9  44.6  32.7  36.2   71.7   8.6         2ND   1.0  2016  \n",
       "1  ...  30.0  57.4  44.1  36.2  33.9   66.7   8.9   Champions   2.0  2016  \n",
       "2  ...  26.0  52.9  46.5  37.4  36.9   65.5   2.3          E8   6.0  2016  \n",
       "3  ...  33.4  52.6  46.3  40.3  34.7   61.9   8.6          E8   1.0  2016  \n",
       "4  ...  37.3  52.7  43.4  41.3  32.5   70.1  11.6          E8   1.0  2016  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%206/cbb.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1406, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Column\n",
    "\n",
    "Next we'll add a column that will contain \"true\" if the wins above bubble are over 7 and \"false\" if not. We'll call this column Win Index or \"windex\" for short.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original IBM assignment had neglected to include 2nd and champions in the F4 class. Below we fix it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>...</th>\n",
       "      <th>2P_O</th>\n",
       "      <th>2P_D</th>\n",
       "      <th>3P_O</th>\n",
       "      <th>3P_D</th>\n",
       "      <th>ADJ_T</th>\n",
       "      <th>WAB</th>\n",
       "      <th>POSTSEASON</th>\n",
       "      <th>SEED</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>windex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>ACC</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>123.3</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>52.6</td>\n",
       "      <td>48.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>53.9</td>\n",
       "      <td>44.6</td>\n",
       "      <td>32.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>71.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>F4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Villanova</td>\n",
       "      <td>BE</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>123.1</td>\n",
       "      <td>90.9</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>56.1</td>\n",
       "      <td>46.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>57.4</td>\n",
       "      <td>44.1</td>\n",
       "      <td>36.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>66.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>F4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>ACC</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>118.3</td>\n",
       "      <td>103.3</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>54.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>...</td>\n",
       "      <td>52.9</td>\n",
       "      <td>46.5</td>\n",
       "      <td>37.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>65.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>E8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>ACC</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>119.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>54.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>...</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.3</td>\n",
       "      <td>40.3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>61.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>B12</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>120.9</td>\n",
       "      <td>90.4</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>55.7</td>\n",
       "      <td>45.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>...</td>\n",
       "      <td>52.7</td>\n",
       "      <td>43.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>70.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>P12</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>118.4</td>\n",
       "      <td>96.2</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>52.3</td>\n",
       "      <td>48.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>...</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.1</td>\n",
       "      <td>34.4</td>\n",
       "      <td>36.2</td>\n",
       "      <td>69.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Syracuse</td>\n",
       "      <td>ACC</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>111.9</td>\n",
       "      <td>93.6</td>\n",
       "      <td>0.8857</td>\n",
       "      <td>50.0</td>\n",
       "      <td>47.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>...</td>\n",
       "      <td>47.2</td>\n",
       "      <td>48.1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.7</td>\n",
       "      <td>65.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>F4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>B12</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>118.2</td>\n",
       "      <td>94.1</td>\n",
       "      <td>0.9326</td>\n",
       "      <td>54.3</td>\n",
       "      <td>47.2</td>\n",
       "      <td>18.3</td>\n",
       "      <td>...</td>\n",
       "      <td>48.2</td>\n",
       "      <td>45.3</td>\n",
       "      <td>42.2</td>\n",
       "      <td>33.7</td>\n",
       "      <td>70.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>F4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Davidson</td>\n",
       "      <td>A10</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>113.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.6767</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>51.1</td>\n",
       "      <td>52.2</td>\n",
       "      <td>35.5</td>\n",
       "      <td>34.3</td>\n",
       "      <td>71.3</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Duquesne</td>\n",
       "      <td>A10</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>108.2</td>\n",
       "      <td>105.1</td>\n",
       "      <td>0.5851</td>\n",
       "      <td>53.9</td>\n",
       "      <td>49.4</td>\n",
       "      <td>18.9</td>\n",
       "      <td>...</td>\n",
       "      <td>53.1</td>\n",
       "      <td>42.8</td>\n",
       "      <td>36.6</td>\n",
       "      <td>40.2</td>\n",
       "      <td>73.6</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fordham</td>\n",
       "      <td>A10</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>101.8</td>\n",
       "      <td>100.4</td>\n",
       "      <td>0.5388</td>\n",
       "      <td>51.5</td>\n",
       "      <td>51.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>...</td>\n",
       "      <td>51.2</td>\n",
       "      <td>52.3</td>\n",
       "      <td>34.6</td>\n",
       "      <td>33.4</td>\n",
       "      <td>67.5</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>George Mason</td>\n",
       "      <td>A10</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>101.4</td>\n",
       "      <td>103.1</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>45.1</td>\n",
       "      <td>48.4</td>\n",
       "      <td>18.6</td>\n",
       "      <td>...</td>\n",
       "      <td>45.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>35.3</td>\n",
       "      <td>68.6</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>A10</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>114.9</td>\n",
       "      <td>99.1</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>50.8</td>\n",
       "      <td>48.7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>...</td>\n",
       "      <td>48.4</td>\n",
       "      <td>48.2</td>\n",
       "      <td>37.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.2</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>La Salle</td>\n",
       "      <td>A10</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>99.2</td>\n",
       "      <td>105.3</td>\n",
       "      <td>0.3358</td>\n",
       "      <td>47.7</td>\n",
       "      <td>53.3</td>\n",
       "      <td>18.8</td>\n",
       "      <td>...</td>\n",
       "      <td>45.4</td>\n",
       "      <td>51.1</td>\n",
       "      <td>33.6</td>\n",
       "      <td>38.1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-12.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>A10</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>102.1</td>\n",
       "      <td>100.7</td>\n",
       "      <td>0.5394</td>\n",
       "      <td>49.1</td>\n",
       "      <td>48.3</td>\n",
       "      <td>17.5</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>71.6</td>\n",
       "      <td>-8.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TEAM CONF   G   W  ADJOE  ADJDE  BARTHAG  EFG_O  EFG_D   TOR  \\\n",
       "0      North Carolina  ACC  40  33  123.3   94.9   0.9531   52.6   48.1  15.4   \n",
       "1           Villanova   BE  40  35  123.1   90.9   0.9703   56.1   46.7  16.3   \n",
       "2          Notre Dame  ACC  36  24  118.3  103.3   0.8269   54.0   49.5  15.3   \n",
       "3            Virginia  ACC  37  29  119.9   91.0   0.9600   54.8   48.4  15.1   \n",
       "4              Kansas  B12  37  32  120.9   90.4   0.9662   55.7   45.1  17.8   \n",
       "5              Oregon  P12  37  30  118.4   96.2   0.9163   52.3   48.9  16.1   \n",
       "6            Syracuse  ACC  37  23  111.9   93.6   0.8857   50.0   47.3  18.1   \n",
       "7            Oklahoma  B12  37  29  118.2   94.1   0.9326   54.3   47.2  18.3   \n",
       "8            Davidson  A10  32  19  113.0  106.0   0.6767   52.0   52.0  14.2   \n",
       "9            Duquesne  A10  33  16  108.2  105.1   0.5851   53.9   49.4  18.9   \n",
       "10            Fordham  A10  30  16  101.8  100.4   0.5388   51.5   51.4  20.4   \n",
       "11       George Mason  A10  32  11  101.4  103.1   0.4507   45.1   48.4  18.6   \n",
       "12  George Washington  A10  38  28  114.9   99.1   0.8454   50.8   48.7  16.5   \n",
       "13           La Salle  A10  30   8   99.2  105.3   0.3358   47.7   53.3  18.8   \n",
       "14      Massachusetts  A10  32  14  102.1  100.7   0.5394   49.1   48.3  17.5   \n",
       "\n",
       "    ...  2P_O  2P_D  3P_O  3P_D  ADJ_T   WAB  POSTSEASON  SEED  YEAR  windex  \n",
       "0   ...  53.9  44.6  32.7  36.2   71.7   8.6          F4   1.0  2016    True  \n",
       "1   ...  57.4  44.1  36.2  33.9   66.7   8.9          F4   2.0  2016    True  \n",
       "2   ...  52.9  46.5  37.4  36.9   65.5   2.3          E8   6.0  2016   False  \n",
       "3   ...  52.6  46.3  40.3  34.7   61.9   8.6          E8   1.0  2016    True  \n",
       "4   ...  52.7  43.4  41.3  32.5   70.1  11.6          E8   1.0  2016    True  \n",
       "5   ...  52.6  46.1  34.4  36.2   69.0   6.7          E8   1.0  2016   False  \n",
       "6   ...  47.2  48.1  36.0  30.7   65.5  -0.3          F4  10.0  2016   False  \n",
       "7   ...  48.2  45.3  42.2  33.7   70.8   8.0          F4   2.0  2016    True  \n",
       "8   ...  51.1  52.2  35.5  34.3   71.3  -2.1         NaN   NaN  2016   False  \n",
       "9   ...  53.1  42.8  36.6  40.2   73.6  -7.8         NaN   NaN  2016   False  \n",
       "10  ...  51.2  52.3  34.6  33.4   67.5  -6.0         NaN   NaN  2016   False  \n",
       "11  ...  45.7  46.0  29.2  35.3   68.6 -11.6         NaN   NaN  2016   False  \n",
       "12  ...  48.4  48.2  37.1  33.0   67.2  -0.8         NaN   NaN  2016   False  \n",
       "13  ...  45.4  51.1  33.6  38.1   67.0 -12.6         NaN   NaN  2016   False  \n",
       "14  ...  48.8  49.0  33.0  31.3   71.6  -8.7         NaN   NaN  2016   False  \n",
       "\n",
       "[15 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['windex'] = np.where(df.WAB > 7, 'True', 'False')\n",
    "#this is the correction\n",
    "df_new= df.replace({'POSTSEASON':['2ND', 'Champions']}, {'POSTSEASON':['F4', 'F4']})\n",
    "df_new.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Data visualization and pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we'll filter the data set to the teams that made the Sweet Sixteen, the Elite Eight, and the Final Four in the post season. We'll also create a new dataframe that will hold the values with the new column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>...</th>\n",
       "      <th>2P_O</th>\n",
       "      <th>2P_D</th>\n",
       "      <th>3P_O</th>\n",
       "      <th>3P_D</th>\n",
       "      <th>ADJ_T</th>\n",
       "      <th>WAB</th>\n",
       "      <th>POSTSEASON</th>\n",
       "      <th>SEED</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>windex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>ACC</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>123.3</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>52.6</td>\n",
       "      <td>48.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>53.9</td>\n",
       "      <td>44.6</td>\n",
       "      <td>32.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>71.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>F4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Villanova</td>\n",
       "      <td>BE</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>123.1</td>\n",
       "      <td>90.9</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>56.1</td>\n",
       "      <td>46.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>57.4</td>\n",
       "      <td>44.1</td>\n",
       "      <td>36.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>66.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>F4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>ACC</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>118.3</td>\n",
       "      <td>103.3</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>54.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>...</td>\n",
       "      <td>52.9</td>\n",
       "      <td>46.5</td>\n",
       "      <td>37.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>65.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>E8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>ACC</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>119.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>54.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>...</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.3</td>\n",
       "      <td>40.3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>61.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>B12</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>120.9</td>\n",
       "      <td>90.4</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>55.7</td>\n",
       "      <td>45.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>...</td>\n",
       "      <td>52.7</td>\n",
       "      <td>43.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>70.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TEAM CONF   G   W  ADJOE  ADJDE  BARTHAG  EFG_O  EFG_D   TOR  \\\n",
       "0  North Carolina  ACC  40  33  123.3   94.9   0.9531   52.6   48.1  15.4   \n",
       "1       Villanova   BE  40  35  123.1   90.9   0.9703   56.1   46.7  16.3   \n",
       "2      Notre Dame  ACC  36  24  118.3  103.3   0.8269   54.0   49.5  15.3   \n",
       "3        Virginia  ACC  37  29  119.9   91.0   0.9600   54.8   48.4  15.1   \n",
       "4          Kansas  B12  37  32  120.9   90.4   0.9662   55.7   45.1  17.8   \n",
       "\n",
       "   ...  2P_O  2P_D  3P_O  3P_D  ADJ_T   WAB  POSTSEASON  SEED  YEAR  windex  \n",
       "0  ...  53.9  44.6  32.7  36.2   71.7   8.6          F4   1.0  2016    True  \n",
       "1  ...  57.4  44.1  36.2  33.9   66.7   8.9          F4   2.0  2016    True  \n",
       "2  ...  52.9  46.5  37.4  36.9   65.5   2.3          E8   6.0  2016   False  \n",
       "3  ...  52.6  46.3  40.3  34.7   61.9   8.6          E8   1.0  2016    True  \n",
       "4  ...  52.7  43.4  41.3  32.5   70.1  11.6          E8   1.0  2016    True  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_new.loc[df_new['POSTSEASON'].str.contains('F4|S16|E8', na=False)] # USE OR OPERATOR, na=False does not fill missing values\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S16    32\n",
       "F4     16\n",
       "E8     16\n",
       "Name: POSTSEASON, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['POSTSEASON'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "32 teams made it into the Sweet Sixteen, 16 into the Elite Eight, and 8 made it into the Final Four over 5 seasons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot some columns to underestand data better:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (0.11.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from seaborn) (1.6.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from seaborn) (3.1.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from seaborn) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from seaborn) (1.20.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: six in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Requirement already satisfied: matplotlib==3.1.3 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (3.1.3)\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from matplotlib==3.1.3) (1.20.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from matplotlib==3.1.3) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from matplotlib==3.1.3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from matplotlib==3.1.3) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from matplotlib==3.1.3) (1.3.1)\n",
      "Requirement already satisfied: six in /Users/macuser/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib==3.1.3) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# notice: installing seaborn might takes a few minutes\n",
    "#!conda install -c anaconda seaborn -y\n",
    "!pip install seaborn\n",
    "!pip install matplotlib==3.1.3\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "bins = np.linspace(df1.BARTHAG.min(), df1.BARTHAG.max(), 10)    #create aray of numbers\n",
    "g = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=6)\n",
    "g.map(plt.hist, 'BARTHAG', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(df1.ADJOE.min(), df1.ADJOE.max(), 10)\n",
    "g = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'ADJOE', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Offensive efficiency seems to play a role**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Pre-processing:  Feature selection/extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Lets look at how Adjusted Defense Efficiency plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(df1.ADJDE.min(), df1.ADJDE.max(), 10)\n",
    "g = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'ADJDE', bins=bins, ec=\"k\")\n",
    "g.axes[-1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We see that this data point doesn't impact the ability of a team to get into the Final Four.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Convert Categorical features to numerical values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets look at the postseason:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "windex  POSTSEASON\n",
       "False   S16           0.575\n",
       "        E8            0.250\n",
       "        F4            0.175\n",
       "True    F4            0.375\n",
       "        S16           0.375\n",
       "        E8            0.250\n",
       "Name: POSTSEASON, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby(['windex'])['POSTSEASON'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "13% of teams with 6 or less wins above bubble make it into the final four while 17% of teams with 7 or more do.\n",
    "**correction: including 2nd and champions we see that windex play role, there is 37.5% with 6 or more wins vs 17.5%  with less than 6 wins\n",
    "we will continue nevertheless classification with  all features of original project**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets convert wins above bubble (winindex) under 7 to 0 and over 7 to 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macuser/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>...</th>\n",
       "      <th>2P_O</th>\n",
       "      <th>2P_D</th>\n",
       "      <th>3P_O</th>\n",
       "      <th>3P_D</th>\n",
       "      <th>ADJ_T</th>\n",
       "      <th>WAB</th>\n",
       "      <th>POSTSEASON</th>\n",
       "      <th>SEED</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>windex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>ACC</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>123.3</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>52.6</td>\n",
       "      <td>48.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>53.9</td>\n",
       "      <td>44.6</td>\n",
       "      <td>32.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>71.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>F4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Villanova</td>\n",
       "      <td>BE</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>123.1</td>\n",
       "      <td>90.9</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>56.1</td>\n",
       "      <td>46.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>57.4</td>\n",
       "      <td>44.1</td>\n",
       "      <td>36.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>66.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>F4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>ACC</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>118.3</td>\n",
       "      <td>103.3</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>54.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>...</td>\n",
       "      <td>52.9</td>\n",
       "      <td>46.5</td>\n",
       "      <td>37.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>65.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>E8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>ACC</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>119.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>54.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>...</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.3</td>\n",
       "      <td>40.3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>61.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>B12</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>120.9</td>\n",
       "      <td>90.4</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>55.7</td>\n",
       "      <td>45.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>...</td>\n",
       "      <td>52.7</td>\n",
       "      <td>43.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>70.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TEAM CONF   G   W  ADJOE  ADJDE  BARTHAG  EFG_O  EFG_D   TOR  \\\n",
       "0  North Carolina  ACC  40  33  123.3   94.9   0.9531   52.6   48.1  15.4   \n",
       "1       Villanova   BE  40  35  123.1   90.9   0.9703   56.1   46.7  16.3   \n",
       "2      Notre Dame  ACC  36  24  118.3  103.3   0.8269   54.0   49.5  15.3   \n",
       "3        Virginia  ACC  37  29  119.9   91.0   0.9600   54.8   48.4  15.1   \n",
       "4          Kansas  B12  37  32  120.9   90.4   0.9662   55.7   45.1  17.8   \n",
       "\n",
       "   ...  2P_O  2P_D  3P_O  3P_D  ADJ_T   WAB  POSTSEASON  SEED  YEAR  windex  \n",
       "0  ...  53.9  44.6  32.7  36.2   71.7   8.6          F4   1.0  2016       1  \n",
       "1  ...  57.4  44.1  36.2  33.9   66.7   8.9          F4   2.0  2016       1  \n",
       "2  ...  52.9  46.5  37.4  36.9   65.5   2.3          E8   6.0  2016       0  \n",
       "3  ...  52.6  46.3  40.3  34.7   61.9   8.6          E8   1.0  2016       1  \n",
       "4  ...  52.7  43.4  41.3  32.5   70.1  11.6          E8   1.0  2016       1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['windex'].replace(to_replace=['False','True'], value=[0,1],inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets defind feature sets, X:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>TORD</th>\n",
       "      <th>ORB</th>\n",
       "      <th>...</th>\n",
       "      <th>FTR</th>\n",
       "      <th>FTRD</th>\n",
       "      <th>2P_O</th>\n",
       "      <th>2P_D</th>\n",
       "      <th>3P_O</th>\n",
       "      <th>3P_D</th>\n",
       "      <th>ADJ_T</th>\n",
       "      <th>WAB</th>\n",
       "      <th>SEED</th>\n",
       "      <th>windex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>123.3</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>52.6</td>\n",
       "      <td>48.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>18.2</td>\n",
       "      <td>40.7</td>\n",
       "      <td>...</td>\n",
       "      <td>32.3</td>\n",
       "      <td>30.4</td>\n",
       "      <td>53.9</td>\n",
       "      <td>44.6</td>\n",
       "      <td>32.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>71.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>123.1</td>\n",
       "      <td>90.9</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>56.1</td>\n",
       "      <td>46.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>28.2</td>\n",
       "      <td>...</td>\n",
       "      <td>34.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57.4</td>\n",
       "      <td>44.1</td>\n",
       "      <td>36.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>66.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>118.3</td>\n",
       "      <td>103.3</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>54.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>32.7</td>\n",
       "      <td>...</td>\n",
       "      <td>32.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>52.9</td>\n",
       "      <td>46.5</td>\n",
       "      <td>37.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>65.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>119.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>54.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>29.9</td>\n",
       "      <td>...</td>\n",
       "      <td>32.1</td>\n",
       "      <td>33.4</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.3</td>\n",
       "      <td>40.3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>61.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>120.9</td>\n",
       "      <td>90.4</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>55.7</td>\n",
       "      <td>45.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>18.5</td>\n",
       "      <td>32.2</td>\n",
       "      <td>...</td>\n",
       "      <td>38.6</td>\n",
       "      <td>37.3</td>\n",
       "      <td>52.7</td>\n",
       "      <td>43.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>70.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    G   W  ADJOE  ADJDE  BARTHAG  EFG_O  EFG_D   TOR  TORD   ORB  ...   FTR  \\\n",
       "0  40  33  123.3   94.9   0.9531   52.6   48.1  15.4  18.2  40.7  ...  32.3   \n",
       "1  40  35  123.1   90.9   0.9703   56.1   46.7  16.3  20.6  28.2  ...  34.1   \n",
       "2  36  24  118.3  103.3   0.8269   54.0   49.5  15.3  14.8  32.7  ...  32.9   \n",
       "3  37  29  119.9   91.0   0.9600   54.8   48.4  15.1  18.8  29.9  ...  32.1   \n",
       "4  37  32  120.9   90.4   0.9662   55.7   45.1  17.8  18.5  32.2  ...  38.6   \n",
       "\n",
       "   FTRD  2P_O  2P_D  3P_O  3P_D  ADJ_T   WAB  SEED  windex  \n",
       "0  30.4  53.9  44.6  32.7  36.2   71.7   8.6   1.0       1  \n",
       "1  30.0  57.4  44.1  36.2  33.9   66.7   8.9   2.0       1  \n",
       "2  26.0  52.9  46.5  37.4  36.9   65.5   2.3   6.0       0  \n",
       "3  33.4  52.6  46.3  40.3  34.7   61.9   8.6   1.0       1  \n",
       "4  37.3  52.7  43.4  41.3  32.5   70.1  11.6   1.0       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df1[['G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D',\n",
    "       'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P_O', '2P_D', '3P_O',\n",
    "       '3P_D', 'ADJ_T', 'WAB', 'SEED', 'windex']]\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "What are our lables? Round where the given team was eliminated or where their season ended (R68 = First Four, R64 = Round of 64, R32 = Round of 32, S16 = Sweet Sixteen, E8 = Elite Eight, F4 = Final Four, 2ND = Runner-up, Champion = Winner of the NCAA March Madness Tournament for that given year)|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F4', 'F4', 'E8', 'E8', 'E8'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df1['POSTSEASON'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Normalize Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Data Standardization give data zero mean and unit variance (technically should be done after train test split )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.14084339,  1.200327  ,  1.27099005,  0.36932205,  0.76705911,\n",
       "        -0.46974302,  0.30923174, -0.96858472, -0.30520594,  2.14127026,\n",
       "         0.60713448, -0.57909905, -0.00976731,  0.28066701, -0.69049988,\n",
       "        -1.58025802,  1.32656749,  1.0052157 ,  0.85148926, -1.03362279,\n",
       "         1.29099445],\n",
       "       [ 2.14084339,  1.75499074,  1.22685366, -0.75489252,  1.21828482,\n",
       "         0.8229159 , -0.35046264, -0.37945611,  0.73195407, -0.99095905,\n",
       "         0.37446019, -0.14250081, -0.09042637,  1.43848303, -0.895853  ,\n",
       "        -0.23022829,  0.35892262, -0.65887651,  0.94743171, -0.7028635 ,\n",
       "         1.29099445],\n",
       "       [-0.58580292, -1.29565983,  0.16758035,  2.73017266, -2.54367836,\n",
       "         0.04732055,  0.96892611, -1.03404346, -1.77451594,  0.1366435 ,\n",
       "         1.4214945 , -0.4335663 , -0.89701696, -0.05013757,  0.08984199,\n",
       "         0.23263905,  1.6210681 , -1.05825864, -1.16330223,  0.62017367,\n",
       "        -0.77459667],\n",
       "       [ 0.09585866,  0.09099952,  0.52067145, -0.72678716,  0.94807408,\n",
       "         0.34278545,  0.45059482, -1.16496093, -0.04591594, -0.56497586,\n",
       "        -1.25425985, -0.62760996,  0.59517564, -0.14937894,  0.00770074,\n",
       "         1.35123512,  0.69549475, -2.25640504,  0.85148926, -1.03362279,\n",
       "         1.29099445],\n",
       "       [ 0.09585866,  0.92299513,  0.74135339, -0.89541934,  1.1107252 ,\n",
       "         0.67518345, -1.10439907,  0.60242492, -0.17556094,  0.01135433,\n",
       "        -0.20722554,  0.94899478,  1.38160147, -0.11629848, -1.18334737,\n",
       "         1.7369579 , -0.2300786 ,  0.47270619,  1.81091378, -1.03362279,\n",
       "         1.29099445]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Training and Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Split the data into Training and Validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (51, 21) (51,)\n",
      "Validation set: (13, 21) (13,)\n"
     ]
    }
   ],
   "source": [
    "# We split the X into train and test to find the best k\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Validation set:', X_val.shape,  y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, it is your turn, use the training set to build an accurate model. Then use the validation set  to report the accuracy of the model\n",
    "You should use the following algorithm:\n",
    "\n",
    "*   K Nearest Neighbor(KNN)\n",
    "*   Decision Tree\n",
    "*   Support Vector Machine\n",
    "*   Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor(KNN)\n",
    "\n",
    "<b>Question  1 </b> Build a KNN model using a value of k equals five, find the accuracy on the validation data (X_val and y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use <code> accuracy_score</cdoe>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Evaluation set Accuracy:  0.6153846153846154 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 5\n",
    "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "neigh\n",
    "yhat=neigh.predict(X_val)\n",
    "print(\"\\033[1m Evaluation set Accuracy: \", accuracy_score(y_val, yhat), '\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question  2</b> Determine and print the accuracy for the first 15 values of k the on the validation data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation set Accuracy for k= 1 is: 0.46153846153846156\n",
      "Evaluation set Accuracy for k= 2 is: 0.5384615384615384\n",
      "Evaluation set Accuracy for k= 3 is: 0.5384615384615384\n",
      "Evaluation set Accuracy for k= 4 is: 0.38461538461538464\n",
      "Evaluation set Accuracy for k= 5 is: 0.6153846153846154\n",
      "Evaluation set Accuracy for k= 6 is: 0.5384615384615384\n",
      "Evaluation set Accuracy for k= 7 is: 0.6923076923076923\n",
      "Evaluation set Accuracy for k= 8 is: 0.46153846153846156\n",
      "Evaluation set Accuracy for k= 9 is: 0.6153846153846154\n",
      "Evaluation set Accuracy for k= 10 is: 0.6923076923076923\n",
      "Evaluation set Accuracy for k= 11 is: 0.6923076923076923\n",
      "Evaluation set Accuracy for k= 12 is: 0.5384615384615384\n",
      "Evaluation set Accuracy for k= 13 is: 0.5384615384615384\n",
      "Evaluation set Accuracy for k= 14 is: 0.5384615384615384\n",
      "Evaluation set Accuracy for k= 15 is: 0.46153846153846156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       k  accuracy\n",
       "0    1.0  0.461538\n",
       "1    2.0  0.538462\n",
       "2    3.0  0.538462\n",
       "3    4.0  0.384615\n",
       "4    5.0  0.615385\n",
       "5    6.0  0.538462\n",
       "6    7.0  0.692308\n",
       "7    8.0  0.461538\n",
       "8    9.0  0.615385\n",
       "9   10.0  0.692308\n",
       "10  11.0  0.692308\n",
       "11  12.0  0.538462\n",
       "12  13.0  0.538462\n",
       "13  14.0  0.538462\n",
       "14  15.0  0.461538"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbe595b1400>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_df=pd.DataFrame(columns=['k', 'accuracy']) #optional: define dataframe for graphing\n",
    "for k in range(15):\n",
    "    neighk = KNeighborsClassifier(n_neighbors = k+1).fit(X_train,y_train)\n",
    "    yhatk=neighk.predict(X_val)\n",
    "    acc=accuracy_score(y_val, yhatk)\n",
    "    print(\"Evaluation set Accuracy for k=\", k+1, 'is:', acc )\n",
    "    acc_df=acc_df.append({'k':k+1, 'accuracy': acc}, ignore_index = True)\n",
    "display(acc_df)\n",
    "\n",
    "#optional: graph below show the variation of accuracy vs k\n",
    "sns.lineplot(data=acc_df, x='k', y='accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**: Based on Accuracy **k=6** is chosen for **KNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code fit a <code>DecisionTreeClassifier</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question  3</b> Determine the minumum   value for the parameter <code>max_depth</code> that improves results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees's Accuracy on val data for max depth 1 and criterion entropy is: 0.46153846153846156\n",
      "DecisionTrees's Accuracy on val data for max depth 2 and criterion entropy is: 0.6153846153846154\n",
      "DecisionTrees's Accuracy on val data for max depth 3 and criterion entropy is: 0.6153846153846154\n",
      "DecisionTrees's Accuracy on val data for max depth 4 and criterion entropy is: 0.6153846153846154\n",
      "DecisionTrees's Accuracy on val data for max depth 5 and criterion entropy is: 0.6153846153846154\n",
      "DecisionTrees's Accuracy on val data for max depth 6 and criterion entropy is: 0.6153846153846154\n",
      "DecisionTrees's Accuracy on val data for max depth 7 and criterion entropy is: 0.6153846153846154\n",
      "DecisionTrees's Accuracy on val data for max depth 8 and criterion entropy is: 0.6153846153846154\n",
      "DecisionTrees's Accuracy on val data for max depth 9 and criterion entropy is: 0.6153846153846154\n",
      "DecisionTrees's Accuracy on val data for max depth 10 and criterion entropy is: 0.6153846153846154\n",
      "DecisionTrees's Accuracy on val data for max depth 1 and criterion gini is: 0.46153846153846156\n",
      "DecisionTrees's Accuracy on val data for max depth 2 and criterion gini is: 0.6153846153846154\n",
      "DecisionTrees's Accuracy on val data for max depth 3 and criterion gini is: 0.38461538461538464\n",
      "DecisionTrees's Accuracy on val data for max depth 4 and criterion gini is: 0.38461538461538464\n",
      "DecisionTrees's Accuracy on val data for max depth 5 and criterion gini is: 0.38461538461538464\n",
      "DecisionTrees's Accuracy on val data for max depth 6 and criterion gini is: 0.3076923076923077\n",
      "DecisionTrees's Accuracy on val data for max depth 7 and criterion gini is: 0.3076923076923077\n",
      "DecisionTrees's Accuracy on val data for max depth 8 and criterion gini is: 0.3076923076923077\n",
      "DecisionTrees's Accuracy on val data for max depth 9 and criterion gini is: 0.3076923076923077\n",
      "DecisionTrees's Accuracy on val data for max depth 10 and criterion gini is: 0.3076923076923077\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>criterion</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth criterion  accuracy\n",
       "11         2      gini  0.615385\n",
       "2          3   entropy  0.615385\n",
       "3          4   entropy  0.615385\n",
       "4          5   entropy  0.615385\n",
       "5          6   entropy  0.615385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>criterion</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth criterion  accuracy\n",
       "11         2      gini  0.615385\n",
       "2          3   entropy  0.615385\n",
       "3          4   entropy  0.615385\n",
       "4          5   entropy  0.615385\n",
       "5          6   entropy  0.615385\n",
       "6          7   entropy  0.615385\n",
       "7          8   entropy  0.615385\n",
       "8          9   entropy  0.615385\n",
       "9         10   entropy  0.615385\n",
       "1          2   entropy  0.615385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_tree_df=pd.DataFrame(columns=['max_depth','criterion', 'accuracy' ]) #define dataframe to store depth vs accuracy\n",
    "for crit in [\"entropy\", 'gini']:\n",
    "    for mxd in range(10):\n",
    "        #set random_state to avoid tree-objects giving random results. Sample is small and we probably have overfitting \n",
    "        BBTree = DecisionTreeClassifier(criterion=crit, max_depth = mxd+1, random_state=0)\n",
    "        BBTree.fit(X_train,y_train)\n",
    "        yhat_tree=BBTree.predict(X_val)\n",
    "        #yhat=BBTree.predict(X_train)\n",
    "        \n",
    "        acc_tree=accuracy_score(y_val, yhat_tree)\n",
    "        print(\"DecisionTrees's Accuracy on val data for max depth\",mxd+1,\"and criterion\", crit, \"is:\" ,acc_tree)\n",
    "        acc_tree_df=acc_tree_df.append({'max_depth':mxd+1,'criterion': crit, 'accuracy': acc_tree}, ignore_index = True)\n",
    "    \n",
    "#method 1 to display top accuracy\n",
    "acc_tree_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "display(acc_tree_df.head())\n",
    "#method 2 to display top accuracy \n",
    "display(acc_tree_df[acc_tree_df['accuracy']== acc_tree_df['accuracy'].max()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**: Based on analysis for both criteria **entropy** and **gini**  the accuracy is max for **max depth =2. But for entropy method only all depths 2-10 give same accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question  4</b>Train the support  vector machine model and determine the accuracy on the validation data for each kernel. Find the kernel (linear, poly, rbf, sigmoid) that provides the best score on the validation data and train a SVM using it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[1m Analysis for linear method \u001b[0m \n",
      "\n",
      " \u001b[1m Accuracy (what is being asked) 0.6154 \u001b[0m \n",
      "\n",
      "The f1 score with micro average is 0.6154 \n",
      "\n",
      "The f1 score with weighted average is 0.6144 \n",
      "\n",
      "Jaccard score for micro average : 0.4444 \n",
      "\n",
      "Jaccard score for weighted average : 0.4500 \n",
      "\n",
      " \u001b[1m Analysis for rbf method \u001b[0m \n",
      "\n",
      " \u001b[1m Accuracy (what is being asked) 0.4615 \u001b[0m \n",
      "\n",
      "The f1 score with micro average is 0.4615 \n",
      "\n",
      "The f1 score with weighted average is 0.4000 \n",
      "\n",
      "Jaccard score for micro average : 0.3000 \n",
      "\n",
      "Jaccard score for weighted average : 0.2704 \n",
      "\n",
      " \u001b[1m Analysis for poly method \u001b[0m \n",
      "\n",
      " \u001b[1m Accuracy (what is being asked) 0.5385 \u001b[0m \n",
      "\n",
      "The f1 score with micro average is 0.5385 \n",
      "\n",
      "The f1 score with weighted average is 0.4308 \n",
      "\n",
      "Jaccard score for micro average : 0.3684 \n",
      "\n",
      "Jaccard score for weighted average : 0.3077 \n",
      "\n",
      " \u001b[1m Analysis for sigmoid method \u001b[0m \n",
      "\n",
      " \u001b[1m Accuracy (what is being asked) 0.4615 \u001b[0m \n",
      "\n",
      "The f1 score with micro average is 0.4615 \n",
      "\n",
      "The f1 score with weighted average is 0.4652 \n",
      "\n",
      "Jaccard score for micro average : 0.3000 \n",
      "\n",
      "Jaccard score for weighted average : 0.3033 \n",
      "\n",
      "Ranked in order of accuracy only \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  accuracy\n",
       "0   linear  0.615385\n",
       "2     poly  0.538462\n",
       "1      rbf  0.461538\n",
       "3  sigmoid  0.461538"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[1m method linear scored max \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   method  accuracy\n",
       "0  linear  0.615385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write your code here\n",
    "#possible kernels: \"linear\", \"rbm\", \"polynomial\", \"sigmoid\"\n",
    "#attn jaccard computed using sklearn uses a different jaccard index than course.(computes average over samples)\n",
    "#in question 5 we will define the standard Jaccard for our purposes\n",
    "kernels=[\"linear\", \"rbf\", \"poly\", \"sigmoid\"]\n",
    "acc_svm_df=pd.DataFrame(columns=['method', 'accuracy']) #define dataframe to store method vs accuracy\n",
    "\n",
    "for iter, kernel in enumerate(kernels):\n",
    "    clf = svm.SVC(kernel=kernel)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_svm = clf.predict(X_val)\n",
    "\n",
    "    print(\" \\033[1m Analysis for\", kernel, \"method \\033[0m \\n\")\n",
    "    acc_svm=accuracy_score(y_val, yhat_svm)\n",
    "    #store accuracy\n",
    "    acc_svm_df=acc_svm_df.append({'method':kernel, 'accuracy': acc_svm}, ignore_index = True)\n",
    "\n",
    "    print(\" \\033[1m Accuracy (what is being asked) %.4f\" %acc_svm,'\\033[0m \\n' )\n",
    "    #micro computes essentially f1 for micro averaged Precision and recall\n",
    "    # this is an average where we take i.e essentially the accuracy (TP+TN)/(TP+TN+FP+FN)\n",
    "    print(\"The f1 score with micro average is %.4f\" %f1_score(y_val,yhat_svm, average='micro'), \"\\n\")\n",
    "    #agrees with accuracy\n",
    "    print(\"The f1 score with weighted average is %.4f\" %f1_score(y_val,yhat_svm, average='weighted'), \"\\n\")\n",
    "    print(\"Jaccard score for micro average : %.4f\" % jaccard_score(y_val, yhat_svm,average='micro'), '\\n')\n",
    "    print(\"Jaccard score for weighted average : %.4f\" % jaccard_score(y_val, yhat_svm,average='weighted'), '\\n')\n",
    "    \n",
    "   \n",
    "#method 1 to display top accuracy\n",
    "print(\"Ranked in order of accuracy only \\n\")\n",
    "acc_svm_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "display(acc_svm_df.head())\n",
    "print(\" \\033[1m method\",acc_svm_df.iat[0,0], \"scored max \\033[0m\")\n",
    "display(acc_svm_df[acc_svm_df['accuracy']== acc_svm_df['accuracy'].max()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector machines**:Based on accuracy only  kernel **linear** is best. Also is micro-average Jaccard score is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question 5</b> Train a logistic regression model and determine the accuracy of the validation data (set C=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[1m Analysis for newton-cg method \u001b[0m \n",
      "\n",
      " \u001b[1m Accuracy (what is being asked) 0.5385 \u001b[0m \n",
      "\n",
      "The f1 score with micro average is 0.5385 \n",
      "\n",
      "The f1 score with weighted average is 0.4308 \n",
      "\n",
      "Jaccard score for micro average : 0.3684 \n",
      "\n",
      "Jaccard score for weighted average : 0.3077 \n",
      "\n",
      "Log-loss: 1.0262 \n",
      "\n",
      " \u001b[1m Analysis for lbfgs method \u001b[0m \n",
      "\n",
      " \u001b[1m Accuracy (what is being asked) 0.5385 \u001b[0m \n",
      "\n",
      "The f1 score with micro average is 0.5385 \n",
      "\n",
      "The f1 score with weighted average is 0.4308 \n",
      "\n",
      "Jaccard score for micro average : 0.3684 \n",
      "\n",
      "Jaccard score for weighted average : 0.3077 \n",
      "\n",
      "Log-loss: 1.0262 \n",
      "\n",
      " \u001b[1m Analysis for liblinear method \u001b[0m \n",
      "\n",
      " \u001b[1m Accuracy (what is being asked) 0.4615 \u001b[0m \n",
      "\n",
      "The f1 score with micro average is 0.4615 \n",
      "\n",
      "The f1 score with weighted average is 0.4056 \n",
      "\n",
      "Jaccard score for micro average : 0.3000 \n",
      "\n",
      "Jaccard score for weighted average : 0.2756 \n",
      "\n",
      "Log-loss: 1.0744 \n",
      "\n",
      " \u001b[1m Analysis for sag method \u001b[0m \n",
      "\n",
      " \u001b[1m Accuracy (what is being asked) 0.5385 \u001b[0m \n",
      "\n",
      "The f1 score with micro average is 0.5385 \n",
      "\n",
      "The f1 score with weighted average is 0.4308 \n",
      "\n",
      "Jaccard score for micro average : 0.3684 \n",
      "\n",
      "Jaccard score for weighted average : 0.3077 \n",
      "\n",
      "Log-loss: 1.0262 \n",
      "\n",
      " \u001b[1m Analysis for saga method \u001b[0m \n",
      "\n",
      " \u001b[1m Accuracy (what is being asked) 0.5385 \u001b[0m \n",
      "\n",
      "The f1 score with micro average is 0.5385 \n",
      "\n",
      "The f1 score with weighted average is 0.4308 \n",
      "\n",
      "Jaccard score for micro average : 0.3684 \n",
      "\n",
      "Jaccard score for weighted average : 0.3077 \n",
      "\n",
      "Log-loss: 1.0262 \n",
      "\n",
      "\n",
      " \u001b[1m Ranked in order of descending accuracy \u001b[0m \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solver</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>log-loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.026228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.026228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sag</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.026231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saga</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.026224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.074442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      solver  accuracy  log-loss\n",
       "0  newton-cg  0.538462  1.026228\n",
       "1      lbfgs  0.538462  1.026228\n",
       "3        sag  0.538462  1.026231\n",
       "4       saga  0.538462  1.026224\n",
       "2  liblinear  0.461538  1.074442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \u001b[1m Solvers with max  accuracy '\u001b[0m \n",
      "'       solver  accuracy  log-loss\n",
      "0  newton-cg  0.538462  1.026228\n",
      "1      lbfgs  0.538462  1.026228\n",
      "3        sag  0.538462  1.026231\n",
      "4       saga  0.538462  1.026224 \n",
      "\n",
      "\n",
      " \u001b[1m Ranked in order of ascending log-loss \u001b[0m \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solver</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>log-loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saga</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.026224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.026228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.026228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sag</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.026231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.074442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      solver  accuracy  log-loss\n",
       "4       saga  0.538462  1.026224\n",
       "1      lbfgs  0.538462  1.026228\n",
       "0  newton-cg  0.538462  1.026228\n",
       "3        sag  0.538462  1.026231\n",
       "2  liblinear  0.461538  1.074442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[1m Solver  saga  scored min log loss \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#possible solvers: ‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’ solvers\n",
    "solvers=[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\" ]\n",
    "acc_lr_df=pd.DataFrame(columns=['solver', 'accuracy', 'log-loss']) \n",
    "#define dataframe to store method vs accuracy, logloss\n",
    "\n",
    "for iter, solver in enumerate(solvers):\n",
    "    LR=LogisticRegression(C=0.01, solver=solver, random_state=0)\n",
    "    LR.fit(X_train,y_train)\n",
    "    yhat_lr = LR.predict(X_val)\n",
    "    yhat_prob = LR.predict_proba(X_val)\n",
    "    logloss=log_loss(y_val, yhat_prob)\n",
    "    acc_lr=accuracy_score(y_val, yhat_lr)\n",
    "    \n",
    "    print(\" \\033[1m Analysis for\", solver , \"method \\033[0m \\n\")\n",
    "    #store accuracy and log-loss\n",
    "    acc_lr_df=acc_lr_df.append({'solver':solver, 'accuracy': acc_lr, 'log-loss':logloss}, ignore_index = True)\n",
    "    \n",
    "    print(\" \\033[1m Accuracy (what is being asked) %.4f\" %acc_lr,'\\033[0m \\n' )\n",
    "    #micro computes essentially f1 for micro averaged Precision and recall\n",
    "    # this is an average where we take i.e essentially the accuracy (TP+TN)/(TP+TN+FP+FN)\n",
    "    print(\"The f1 score with micro average is %.4f\" %f1_score(y_val,yhat_lr, average='micro'), \"\\n\")\n",
    "    #agrees with accuracy\n",
    "    print(\"The f1 score with weighted average is %.4f\" %f1_score(y_val,yhat_lr, average='weighted'), \"\\n\")\n",
    "    print(\"Jaccard score for micro average : %.4f\" % jaccard_score(y_val, yhat_lr,average='micro'), '\\n')\n",
    "    print(\"Jaccard score for weighted average : %.4f\" % jaccard_score(y_val, yhat_lr,average='weighted'), '\\n')\n",
    "    print(\"Log-loss: %.4f\" %log_loss(y_val, yhat_prob), \"\\n\")\n",
    "\n",
    "        \n",
    "# display top accuracy\n",
    "print(\"\\n \\033[1m Ranked in order of descending accuracy \\033[0m \\n\")\n",
    "acc_lr_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "display(acc_lr_df.head())\n",
    "print(\"\\n \\033[1m Solvers with max  accuracy '\\033[0m \\n'\", acc_lr_df[acc_lr_df['accuracy']== acc_lr_df['accuracy'].max()],'\\n')\n",
    "\n",
    "#display min log loss\n",
    "print(\"\\n \\033[1m Ranked in order of ascending log-loss \\033[0m \\n\")\n",
    "acc_lr_df.sort_values(by='log-loss', ascending=True, inplace=True)\n",
    "display(acc_lr_df.head())\n",
    "print(\" \\033[1m Solver \",acc_lr_df.iat[0,0], \" scored min log loss \\033[0m\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**: Based on the analysis all solvers had the same accuracy, Jaccard/F1-micro. So we cannot disciminate. Log loss gives advantage to **saga** method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation using Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# for f1_score please set the average parameter to 'micro'\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(predictions, true):\n",
    "    if (len(predictions) == len(true)):\n",
    "        intersect = 0;\n",
    "        for x,y in zip(predictions, true):\n",
    "            if (x == y):\n",
    "                intersect += 1\n",
    "        return intersect / (len(predictions) + len(true) - intersect)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question  5</b> Calculate the  F1 score and Jaccard score for each model from above. Use the Hyperparameter that performed best on the validation data. **For f1\\_score please set the average parameter to 'micro'.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Load Test set for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1757, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>...</th>\n",
       "      <th>FTRD</th>\n",
       "      <th>2P_O</th>\n",
       "      <th>2P_D</th>\n",
       "      <th>3P_O</th>\n",
       "      <th>3P_D</th>\n",
       "      <th>ADJ_T</th>\n",
       "      <th>WAB</th>\n",
       "      <th>POSTSEASON</th>\n",
       "      <th>SEED</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>ACC</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>123.3</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>52.6</td>\n",
       "      <td>48.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>30.4</td>\n",
       "      <td>53.9</td>\n",
       "      <td>44.6</td>\n",
       "      <td>32.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>71.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2ND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Villanova</td>\n",
       "      <td>BE</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>123.1</td>\n",
       "      <td>90.9</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>56.1</td>\n",
       "      <td>46.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57.4</td>\n",
       "      <td>44.1</td>\n",
       "      <td>36.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>66.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Champions</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>ACC</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>118.3</td>\n",
       "      <td>103.3</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>54.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>52.9</td>\n",
       "      <td>46.5</td>\n",
       "      <td>37.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>65.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>E8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>ACC</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>119.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>54.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>...</td>\n",
       "      <td>33.4</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.3</td>\n",
       "      <td>40.3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>61.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>B12</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>120.9</td>\n",
       "      <td>90.4</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>55.7</td>\n",
       "      <td>45.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>...</td>\n",
       "      <td>37.3</td>\n",
       "      <td>52.7</td>\n",
       "      <td>43.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>70.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TEAM CONF   G   W  ADJOE  ADJDE  BARTHAG  EFG_O  EFG_D   TOR  \\\n",
       "0  North Carolina  ACC  40  33  123.3   94.9   0.9531   52.6   48.1  15.4   \n",
       "1       Villanova   BE  40  35  123.1   90.9   0.9703   56.1   46.7  16.3   \n",
       "2      Notre Dame  ACC  36  24  118.3  103.3   0.8269   54.0   49.5  15.3   \n",
       "3        Virginia  ACC  37  29  119.9   91.0   0.9600   54.8   48.4  15.1   \n",
       "4          Kansas  B12  37  32  120.9   90.4   0.9662   55.7   45.1  17.8   \n",
       "\n",
       "   ...  FTRD  2P_O  2P_D  3P_O  3P_D  ADJ_T   WAB  POSTSEASON  SEED  YEAR  \n",
       "0  ...  30.4  53.9  44.6  32.7  36.2   71.7   8.6         2ND   1.0  2016  \n",
       "1  ...  30.0  57.4  44.1  36.2  33.9   66.7   8.9   Champions   2.0  2016  \n",
       "2  ...  26.0  52.9  46.5  37.4  36.9   65.5   2.3          E8   6.0  2016  \n",
       "3  ...  33.4  52.6  46.3  40.3  34.7   61.9   8.6          E8   1.0  2016  \n",
       "4  ...  37.3  52.7  43.4  41.3  32.5   70.1  11.6          E8   1.0  2016  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0120ENv3/Dataset/ML0101EN_EDX_skill_up/basketball_train.csv',error_bad_lines=False)\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macuser/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.0237774 ,  1.08826557,  1.22530098,  0.44981368,  0.71518965,\n",
       "        -0.33173773,  0.40209949, -0.92761522, -0.29964277,  2.05898704,\n",
       "         0.56525459, -0.71716081, -0.11377348,  0.36075891, -0.49090361,\n",
       "        -1.52502989,  1.32113889,  1.1464997 ,  0.81747836, -1.06609823,\n",
       "         1.29099445],\n",
       "       [ 2.0237774 ,  1.59150976,  1.18321249, -0.63489151,  1.16064546,\n",
       "         0.85911567, -0.18506013, -0.34431133,  0.67381598, -1.1096603 ,\n",
       "         0.33629071, -0.29956616, -0.18405826,  1.44808393, -0.6782714 ,\n",
       "        -0.18223628,  0.37231158, -0.38727916,  0.90945905, -0.73031926,\n",
       "         1.29099445],\n",
       "       [-0.56665767, -1.1763333 ,  0.17308889,  2.72769459, -2.55321282,\n",
       "         0.14460363,  0.9892591 , -0.99242677, -1.67870933,  0.03105274,\n",
       "         1.36662819, -0.5779626 , -0.88690601,  0.05009462,  0.22109399,\n",
       "         0.27815011,  1.60991241, -0.75538609, -1.11411608,  0.61279662,\n",
       "        -0.77459667],\n",
       "       [ 0.0809511 ,  0.08177718,  0.50979676, -0.60777388,  0.89388995,\n",
       "         0.41679869,  0.5279194 , -1.12204985, -0.05627808, -0.67872426,\n",
       "        -1.26645649, -0.76356022,  0.41336234, -0.04310467,  0.14614688,\n",
       "         1.39075053,  0.70233847, -1.85970687,  0.81747836, -1.06609823,\n",
       "         1.29099445],\n",
       "       [ 0.0809511 ,  0.83664347,  0.72023918, -0.77047966,  1.05446123,\n",
       "         0.72301814, -0.85609969,  0.62786183, -0.17796043, -0.09569315,\n",
       "        -0.23611901,  0.74442047,  1.0986389 , -0.01203824, -0.94058631,\n",
       "         1.77440585, -0.20523547,  0.65569046,  1.73728524, -1.06609823,\n",
       "         1.29099445]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['windex'] = np.where(test_df.WAB > 7, 'True', 'False')\n",
    "test_df_new= test_df.replace({'POSTSEASON':['2ND', 'Champions']}, {'POSTSEASON':['F4', 'F4']})\n",
    "test_df1 = test_df_new[test_df_new['POSTSEASON'].str.contains('F4|S16|E8', na=False)]\n",
    "\n",
    "test_Feature = test_df1[['G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D',\n",
    "       'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P_O', '2P_D', '3P_O',\n",
    "       '3P_D', 'ADJ_T', 'WAB', 'SEED', 'windex']]\n",
    "test_Feature['windex'].replace(to_replace=['False','True'], value=[0,1],inplace=True)\n",
    "test_X=test_Feature\n",
    "test_X= preprocessing.StandardScaler().fit(test_X).transform(test_X)\n",
    "print(test_X.shape)\n",
    "test_X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F4', 'F4', 'E8', 'E8', 'E8'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test_df1['POSTSEASON'].values\n",
    "test_y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m KNN:  we use k=6 as found with evaluation set \u001b[0m\n",
      "Test set Accuracy for k=  6 : 0.6125\n",
      "Test set Jaccard for k=   6 : 0.44144144144144143\n",
      "Test set F1 for k=  6 : 0.6125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 6\n",
    "neigh_knn_test_6 = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "yhat_knn_test_6=neigh_knn_test_6.predict(test_X)\n",
    "\n",
    "print( \"\\033[1m KNN:  we use k=6 as found with evaluation set \\033[0m\")\n",
    "print(\"Test set Accuracy for k= \",k,\":\", accuracy_score(test_y, yhat_knn_test_6))\n",
    "print(\"Test set Jaccard for k=  \",k,\":\", jaccard_index(yhat_knn_test_6, test_y))\n",
    "print(\"Test set F1 for k= \",k,\":\", f1_score(test_y, yhat_knn_test_6, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.495327</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.467890</td>\n",
       "      <td>0.6375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k  accuracy   jaccard  f1_micro\n",
       "0  1.0    0.8250  0.702128    0.8250\n",
       "2  3.0    0.6875  0.523810    0.6875\n",
       "3  4.0    0.6625  0.495327    0.6625\n",
       "4  5.0    0.6500  0.481481    0.6500\n",
       "1  2.0    0.6375  0.467890    0.6375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.495327</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.467890</td>\n",
       "      <td>0.6375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k  accuracy   jaccard  f1_micro\n",
       "0  1.0    0.8250  0.702128    0.8250\n",
       "2  3.0    0.6875  0.523810    0.6875\n",
       "3  4.0    0.6625  0.495327    0.6625\n",
       "4  5.0    0.6500  0.481481    0.6500\n",
       "1  2.0    0.6375  0.467890    0.6375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.8250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.495327</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.467890</td>\n",
       "      <td>0.6375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k  accuracy   jaccard  f1_micro\n",
       "0  1.0    0.8250  0.702128    0.8250\n",
       "2  3.0    0.6875  0.523810    0.6875\n",
       "3  4.0    0.6625  0.495327    0.6625\n",
       "4  5.0    0.6500  0.481481    0.6500\n",
       "1  2.0    0.6375  0.467890    0.6375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#THIS IS EXTRA: for verification purposes we run also k=1-15\n",
    "\n",
    "acc_df_knn_test=pd.DataFrame(columns=['k', 'accuracy', 'jaccard', 'f1_micro']) \n",
    "\n",
    "for k in range(15):\n",
    "    neigh_knn_test = KNeighborsClassifier(n_neighbors = k+1).fit(X_train,y_train)\n",
    "    yhat_knn_test=neigh_knn_test.predict(test_X)\n",
    "    \n",
    "    acc_knn_test=accuracy_score(test_y, yhat_knn_test)\n",
    "    jac_knn_test= jaccard_index(yhat_knn_test, test_y)\n",
    "    f1_knn_test=f1_score(test_y, yhat_knn_test, average='micro')\n",
    "\n",
    "    acc_df_knn_test=acc_df_knn_test.append({'k':k+1, 'accuracy': acc_knn_test, 'jaccard': jac_knn_test, \\\n",
    "                                            'f1_micro': f1_knn_test}, ignore_index = True)\n",
    "\n",
    "\n",
    "acc_df_knn_test.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "display(acc_df_knn_test.head())\n",
    "\n",
    "acc_df_knn_test.sort_values(by='jaccard', ascending=False, inplace=True)\n",
    "display(acc_df_knn_test.head())\n",
    "\n",
    "acc_df_knn_test.sort_values(by='f1_micro', ascending=False, inplace=True)\n",
    "display(acc_df_knn_test.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN-Conclusions** For k=1 we get best values, but given that low k are prone to overfitting, we should try to train on a grid-search and re run for the test set to see what is going on. **k=3 is clearly the best of the rest. Our k=6 from the trained model did well but not as much** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the trained set we had max depth 2 as the best. Lets use those\n",
      "\n",
      "\u001b[1m we use max depth=2 as found with evaluation set \u001b[0m\n",
      " Accuracy for maxdepth=2 0.75\n",
      "Jaccard for maxdepth=2 0.6\n",
      "F1 for maxdepth =2 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"for the trained set we had max depth 2 as the best. Lets use those\\n\")\n",
    "\n",
    "    \n",
    "BBTree_test2 = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 2, random_state=0)\n",
    "BBTree_test2.fit(X_train,y_train)\n",
    "yhat_tree_test2=BBTree_test2.predict(test_X)\n",
    "    \n",
    "print( \"\\033[1m we use max depth=2 as found with evaluation set \\033[0m\")\n",
    "print(\" Accuracy for maxdepth=2\",accuracy_score(test_y, yhat_tree_test2))\n",
    "print(\"Jaccard for maxdepth=2\",jaccard_index(yhat_tree_test2, test_y))\n",
    "print(\"F1 for maxdepth =2\", f1_score(test_y, yhat_tree_test2,average='micro'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxdepth</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.7625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.495327</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   maxdepth  accuracy   jaccard  f1_micro\n",
       "5       6.0    0.8125  0.684211    0.8125\n",
       "4       5.0    0.8000  0.666667    0.8000\n",
       "6       7.0    0.8000  0.666667    0.8000\n",
       "7       8.0    0.7875  0.649485    0.7875\n",
       "8       9.0    0.7875  0.649485    0.7875\n",
       "9      10.0    0.7875  0.649485    0.7875\n",
       "3       4.0    0.7625  0.616162    0.7625\n",
       "1       2.0    0.7500  0.600000    0.7500\n",
       "2       3.0    0.7500  0.600000    0.7500\n",
       "0       1.0    0.6625  0.495327    0.6625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxdepth</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.7625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.495327</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   maxdepth  accuracy   jaccard  f1_micro\n",
       "5       6.0    0.8125  0.684211    0.8125\n",
       "4       5.0    0.8000  0.666667    0.8000\n",
       "6       7.0    0.8000  0.666667    0.8000\n",
       "7       8.0    0.7875  0.649485    0.7875\n",
       "8       9.0    0.7875  0.649485    0.7875\n",
       "9      10.0    0.7875  0.649485    0.7875\n",
       "3       4.0    0.7625  0.616162    0.7625\n",
       "1       2.0    0.7500  0.600000    0.7500\n",
       "2       3.0    0.7500  0.600000    0.7500\n",
       "0       1.0    0.6625  0.495327    0.6625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxdepth</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.7625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.495327</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   maxdepth  accuracy   jaccard  f1_micro\n",
       "5       6.0    0.8125  0.684211    0.8125\n",
       "4       5.0    0.8000  0.666667    0.8000\n",
       "6       7.0    0.8000  0.666667    0.8000\n",
       "7       8.0    0.7875  0.649485    0.7875\n",
       "8       9.0    0.7875  0.649485    0.7875\n",
       "9      10.0    0.7875  0.649485    0.7875\n",
       "3       4.0    0.7625  0.616162    0.7625\n",
       "1       2.0    0.7500  0.600000    0.7500\n",
       "2       3.0    0.7500  0.600000    0.7500\n",
       "0       1.0    0.6625  0.495327    0.6625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#THIS IS EXTRA: for verification purposes\n",
    "acc_df_tree_test=pd.DataFrame(columns=['maxdepth', 'accuracy','jaccard', 'f1_micro']) #define dataframe to store \n",
    "\n",
    "for mxd in range(10):\n",
    "    BBTree_test = DecisionTreeClassifier(criterion=\"entropy\", max_depth = mxd+1, random_state=0)\n",
    "    BBTree_test.fit(X_train,y_train)\n",
    "    yhat_tree_test=BBTree_test.predict(test_X)\n",
    "    \n",
    "    acc_tree_test=accuracy_score(test_y, yhat_tree_test)\n",
    "    jac_tree_test= jaccard_index(yhat_tree_test, test_y)\n",
    "    f1_tree_test=f1_score(test_y, yhat_tree_test, average='micro')\n",
    "\n",
    "    acc_df_tree_test=acc_df_tree_test.append({'maxdepth': mxd+1, 'accuracy': acc_tree_test, 'jaccard': jac_tree_test, \\\n",
    "                                            'f1_micro': f1_tree_test}, ignore_index = True)\n",
    "\n",
    "\n",
    "acc_df_tree_test.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "display(acc_df_tree_test.head(15))\n",
    "\n",
    "acc_df_tree_test.sort_values(by='jaccard', ascending=False, inplace=True)\n",
    "display(acc_df_tree_test.head(15))\n",
    "\n",
    "acc_df_tree_test.sort_values(by='f1_micro', ascending=False, inplace=True)\n",
    "display(acc_df_tree_test.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision-Tree Conclusion**: Although maxdepth 2 gave best results for training-evaluation and gini, for all depths 2-10 we had the same accuracy for entropy. This was already a bit suspicious as depth 2 was low for this number of features. For the test max depth 6,5,7 do a better job. But the point of training and evaluating is to use is for prediction on a test. The test set cannot be used as is for deciding to use max depth 6,5 7 over initial  2. One should go back and retrain the model probably with a Grid search on the original train,evaluation data and then check again with the test. \n",
    "\n",
    "Max depth 2 gave good results in general though, pretty close to the rest. Jaccard results are approx 8% less and accuracy 6% less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the trained set we had linear method as the best. Lets use this\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clf_test_poly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-fee54a281bbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf_test_lin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf_test_lin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0myhat_svm_test_lin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_test_poly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"\\033[1m we use method linear as found with evaluation set \\033[0m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf_test_poly' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"for the trained set we had linear method as the best. Lets use this\\n\")\n",
    "clf_test_lin = svm.SVC(kernel='linear')\n",
    "clf_test_lin.fit(X_train, y_train) \n",
    "yhat_svm_test_lin = clf_test_poly.predict(test_X)\n",
    "    \n",
    "print( \"\\033[1m we use method linear as found with evaluation set \\033[0m\")\n",
    "print(\" Accuracy \",accuracy_score(test_y, yhat_svm_test_lin))\n",
    "print(\"Jaccard\",jaccard_index(yhat_svm_test_lin, test_y))\n",
    "print(\"F1\", f1_score(test_y, yhat_svm_test_lin, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS EXTRA: for verification purposes\n",
    "\n",
    "kernels=[\"linear\", \"rbf\", \"poly\", \"sigmoid\"]\n",
    "acc_df_svm_test=pd.DataFrame(columns=['kernel', 'accuracy','jaccard', 'f1_micro'])\n",
    "\n",
    "for iter, kernel in enumerate(kernels):\n",
    "    clf_test = svm.SVC(kernel=kernel)\n",
    "    clf_test.fit(X_train, y_train) \n",
    "    yhat_svm_test = clf_test.predict(test_X)\n",
    "    \n",
    "    acc_svm_test=accuracy_score(test_y, yhat_svm_test)\n",
    "    jac_svm_test= jaccard_index(yhat_svm_test, test_y)\n",
    "    f1_svm_test=f1_score(test_y, yhat_svm_test,average='micro')\n",
    "\n",
    "    acc_df_svm_test=acc_df_svm_test.append({'kernel': kernel, 'accuracy': acc_svm_test, 'jaccard': jac_svm_test, \\\n",
    "                                            'f1_micro': f1_svm_test}, ignore_index = True)\n",
    "\n",
    "\n",
    "acc_df_svm_test.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "display(acc_df_svm_test.head(15))\n",
    "\n",
    "acc_df_svm_test.sort_values(by='jaccard', ascending=False, inplace=True)\n",
    "display(acc_df_svm_test.head())\n",
    "\n",
    "acc_df_svm_test.sort_values(by='f1_micro', ascending=False, inplace=True)\n",
    "display(acc_df_svm_test.head())\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM Conclusion**: Again  linear, is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For training the saga solver gave the best result\\n\")\n",
    "LR_test_saga=LogisticRegression(C=0.01, solver='saga')\n",
    "LR_test_saga.fit(X_train,y_train)\n",
    "yhat_lr_test_saga = LR_test_saga.predict(test_X)\n",
    "yhat_prob_test_saga = LR_test_saga.predict_proba(test_X)\n",
    "    \n",
    "    \n",
    "print( \"\\033[1m we use solver saga as found with evaluation set \\033[0m\")\n",
    "print(\" Accuracy \",accuracy_score(test_y, yhat_lr_test_saga))\n",
    "print(\"Jaccard\",jaccard_index(yhat_lr_test_saga, test_y))\n",
    "print(\"F1\", f1_score(test_y, yhat_lr_test_saga, average='micro'))\n",
    "print(\"Log-loss\", log_loss(test_y, yhat_prob_test_saga))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#THIS IS EXTRA: for verification purposes\n",
    "\n",
    "#check test set based on all solvers\n",
    "solvers=[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\" ]\n",
    "acc_df_lr_test=pd.DataFrame(columns=['solver', 'accuracy', 'jaccard', 'f1_micro','log-loss']) \n",
    "\n",
    "for iter, solver in enumerate(solvers):\n",
    "    LR_test=LogisticRegression(C=0.01, solver=solver, random_state=0)\n",
    "    LR_test.fit(X_train,y_train)\n",
    "    yhat_lr_test = LR_test.predict(test_X)\n",
    "    yhat_prob_test = LR_test.predict_proba(test_X)\n",
    "    \n",
    "    logloss=log_loss(test_y, yhat_prob_test)\n",
    "    acc_lr_test=accuracy_score(test_y, yhat_lr_test)\n",
    "    jac_lr_test= jaccard_index(yhat_lr_test, test_y)\n",
    "    f1_lr_test=f1_score(test_y, yhat_lr_test, average='micro')\n",
    "\n",
    "    acc_df_lr_test=acc_df_lr_test.append({'solver': solver, 'accuracy': acc_lr_test, 'jaccard': jac_lr_test, \\\n",
    "                                            'f1_micro': f1_lr_test, 'log-loss':logloss}, ignore_index = True)\n",
    "\n",
    "\n",
    "acc_df_lr_test.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "display(acc_df_lr_test.head())\n",
    "\n",
    "acc_df_lr_test.sort_values(by='jaccard', ascending=False, inplace=True)\n",
    "display(acc_df_lr_test.head())\n",
    "\n",
    "acc_df_lr_test.sort_values(by='f1_micro', ascending=False, inplace=True)\n",
    "display(acc_df_lr_test.head())\n",
    "\n",
    "acc_df_lr_test.sort_values(by='log-loss', ascending=True, inplace=True)\n",
    "display(acc_df_lr_test.head())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**: Liblinear scored max on accuracy, Jaccard and F1. Saga did the second best in all scores (same as the rest of the methods)\n",
    "But saga did clearly better than liblinear in logloss. Original choice of Saga was based on tie with liblinear and all other solvers in the training set, but clear advantage in log-loss. Here we see that liblinear seems to outperform all solvers in accuracy, but still ranks last in logloss\n",
    "\n",
    "Given that accuracy of saga is still good (>55%) and logloss minimum, saga seems good for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "You should be able to report the accuracy of the built model using different evaluation metrics:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm          | Accuracy | Jaccard  | F1-score  | LogLoss |\n",
    "|--------------------|----------|----------|-----------|---------|\n",
    "| KNN  (k=6)         | 0.6125   | 0.441441 | 0.6125    | NA      |\n",
    "| Decision Tree(dp=2)| 0.750000 | 0.600000 | 0.750000  | NA      |\n",
    "| SVM   (linear)     | 0.787500 | 0.649484 | 0.787500  | NA      |\n",
    "| LogisticRegression | 0.612500 | 0.441441 | 0.612500  |0.897210 |\n",
    "saga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performers on given test\n",
    "\n",
    "\n",
    "\n",
    "| Algorithm          | Accuracy | Jaccard  | F1-score  | LogLoss |\n",
    "|--------------------|----------|----------|-----------|---------|\n",
    "| KNN  (k=3)         | 0.687500 | 0.523881 | 0.687500  | NA      |\n",
    "| Decision Tree(dp=6)| 0.812500 | 0.684211 | 0.812500  | NA      |\n",
    "| SVM   (linear)     | 0.787500 | 0.649484 | 0.787500  | NA      |\n",
    "| LogisticRegression | 0.637500 | 0.467889 | 0.637500  |0.999444 |\n",
    "liblinear\n",
    "\n",
    "**Summary**\n",
    "\n",
    "**KNN-Conclusions** For k=1 we get best values, but given that low k are prone to overfitting, we should try to train on a grid-search and re run for the test set to see what is going on. **k=3 is clearly the best of the rest. Our k=6 from the trained model did well but not as much** \n",
    "\n",
    "**Decision-Tree Conclusion**: Although maxdepth 2 gave best results for training-evaluation and gini, for all depths 2-10 we had the same accuracy for entropy. This was already a bit suspicious as depth 2 was low for this number of features. For the test max depth 6,5,7 do a better job. But the point of training and evaluating is to use is for prediction on a test. The test set cannot be used as is for deciding to use max depth 6,5 7 over initial  2. One should go back and retrain the model probably with a Grid search on the original train,evaluation data and then check again with the test. \n",
    "\n",
    "Max depth 2 gave good results in general though, pretty close to the rest. Jaccard results are approx 8% less and accuracy 6% less\n",
    "\n",
    "**SVM Conclusion**: Again  linear, is the best\n",
    "\n",
    "**Logistic Regression**: Liblinear scored max on accuracy, Jaccard and F1. Saga did the second best in all scores (same as the rest of the methods)\n",
    "But saga did clearly better than liblinear in logloss. Original choice of Saga was based on tie with liblinear and all other solvers in the training set, but clear advantage in log-loss. Here we see that liblinear seems to outperform all solvers in accuracy, but still ranks last in logloss\n",
    "\n",
    "Given that accuracy of saga is still good (>55%) and logloss minimum, saga seems good for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something to keep in mind when creating models to predict the results of basketball tournaments or sports in general is that is quite hard due to so many factors influencing the game. Even in sports betting an accuracy of 55% and over is considered good as it indicates profits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h2>Want to learn more?</h2>\n",
    "\n",
    "IBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems – by your enterprise as a whole. A free trial is available through this course, available here: <a href=\"https://www.ibm.com/analytics/spss-statistics-software?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2021-01-01\">SPSS Modeler</a>\n",
    "\n",
    "Also, you can use Watson Studio to run these notebooks faster with bigger datasets. Watson Studio is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, Watson Studio enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of Watson Studio users today with a free account at <a href=\"https://www.ibm.com/cloud/watson-studio?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2021-01-01\">Watson Studio</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "## Author\n",
    "\n",
    "Saeed Aghabozorgi\n",
    "\n",
    "### Other Contributors\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2021-01-01\" target=\"_blank\">Joseph Santarcangelo</a>\n",
    "\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "|2021-04-03   | 2.1  | Malika Singla| Updated the Report accuracy |\n",
    "| 2020-08-27  | 2.0  | Lavanya  |  Moved lab to course repo in GitLab |\n",
    "|   |   |   |   |\n",
    "|   |   |   |   |\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
